{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNSDW/69GpNFcp7JAs0mtE6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ğŸ§  ESN-LM-garage / summer-studio\n","\n","Echo State Networkï¼ˆESNï¼‰ã‚’ä½¿ã£ã¦ã€è‡ªå®…ã‚„Colabä¸Šã§è»½é‡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ã‚¹ã‚¿ãƒ¼ãƒˆã‚»ãƒƒãƒˆã€‚\n","\n"],"metadata":{"id":"11qY2fg9DZKS"}},{"cell_type":"code","source":["!pip install torch numpy scikit-learn tqdm datasets sentencepiece\n"],"metadata":{"id":"R4bWtbXxDqua"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ğŸŒ± æ¦‚è¦\n","\n","ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ãƒªã‚¶ãƒ¼ãƒãƒ¼ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆESNï¼‰ã‚’ä¸­æ ¸ã«ã—ãŸæ–°ã—ã„ã‚¿ã‚¤ãƒ—ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚  \n","é€šå¸¸ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ã‚ˆã†ã«å¤§é‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã›ãšã€**å†…éƒ¨ãƒªã‚¶ãƒãƒ¼ã¯å›ºå®šã•ã‚ŒãŸã‚«ã‚ªã‚¹çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã€‚  \n","å­¦ç¿’å¯¾è±¡ã¯ä¸»ã«ã€Œå‡ºåŠ›å±¤ï¼ˆReadoutï¼‰ã€ã®ã¿ã§ã‚ã‚‹ãŸã‚ã€é«˜é€Ÿã‹ã¤çœãƒ¡ãƒ¢ãƒªã§å­¦ç¿’å¯èƒ½ã€‚\n"],"metadata":{"id":"EiCgiJCCDruk"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","class ESNReservoir(nn.Module):\n","    def __init__(self, in_dim, res_size=1024, spectral_radius=0.9, sparsity=0.02, leak_rate=1.0, device='cuda'):\n","        super().__init__()\n","        self.in_dim = in_dim\n","        self.res_size = res_size\n","        self.leak = leak_rate\n","        self.device = device\n","\n","        Win = torch.randn(res_size, in_dim, device=device) * 0.5\n","        W = torch.randn(res_size, res_size, device=device)\n","        mask = (torch.rand_like(W) < sparsity).float()\n","        W = W * mask\n","\n","        with torch.no_grad():\n","            eigvals = torch.linalg.eigvals(W)\n","            max_ev = max(abs(eigvals).real.max().item(), 1e-6)\n","            W = W * (spectral_radius / max_ev)\n","\n","        self.register_buffer('Win', Win)\n","        self.register_buffer('W', W)\n","        self.state = torch.zeros(1, res_size, device=device)\n","\n","    def forward(self, u):\n","        pre = F.linear(u, self.Win) + F.linear(self.state, self.W)\n","        new_state = (1 - self.leak) * self.state + self.leak * torch.tanh(pre)\n","        self.state = new_state\n","        return new_state\n","\n","    def reset_state(self, batch_size=1):\n","        self.state = torch.zeros(batch_size, self.res_size, device=self.device)\n","\n","class ESNLanguageModel(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=128, res_size=1024, device='cuda'):\n","        super().__init__()\n","        self.device = device\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.reservoir = ESNReservoir(embed_dim, res_size, device=device)\n","        self.readout = nn.Linear(res_size, vocab_size)\n","\n","    def forward(self, input_ids):\n","        self.reservoir.reset_state(batch_size=input_ids.size(0))\n","        outputs = []\n","        for t in range(input_ids.size(1)):\n","            x = self.embedding(input_ids[:, t])\n","            res_state = self.reservoir(x)\n","            logits = self.readout(res_state)\n","            outputs.append(logits.unsqueeze(1))\n","        return torch.cat(outputs, dim=1)\n"],"metadata":{"id":"hNdxwlEtDsM8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import torch\n","\n","dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")  # 1%ã ã‘ä½¿ã†\n","text_data = \"\\n\".join(dataset[\"text\"])\n","\n","from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","tokens = tokenizer(text_data, return_tensors=\"pt\", truncation=True, max_length=256)\n","input_ids = tokens[\"input_ids\"]\n","\n","# ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒãƒƒãƒåˆ†å‰²\n","seq_len = 64\n","inputs = []\n","targets = []\n","for i in range(0, input_ids.size(1) - seq_len - 1, seq_len):\n","    inputs.append(input_ids[:, i:i+seq_len])\n","    targets.append(input_ids[:, i+1:i+seq_len+1])\n","\n","inputs = torch.cat(inputs)\n","targets = torch.cat(targets)\n","print(f\"Dataset size: {inputs.size()}\")\n"],"metadata":{"id":"xuSuYJmZDvYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","vocab_size = tokenizer.vocab_size\n","\n","model = ESNLanguageModel(vocab_size, embed_dim=128, res_size=512, device=device).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n","\n","epochs = 120\n","batch_size = 8\n","\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    for i in tqdm(range(0, inputs.size(0), batch_size)):\n","        batch_in = inputs[i:i+batch_size].to(device)\n","        batch_tg = targets[i:i+batch_size].to(device)\n","\n","        optimizer.zero_grad()\n","        logits = model(batch_in)\n","        loss = F.cross_entropy(logits.view(-1, vocab_size), batch_tg.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}: Loss = {total_loss / max(1, (inputs.size(0)//batch_size)):.4f}\")\n","\n"],"metadata":{"id":"4PqfBGGXDztg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_text(model, tokenizer, prompt=\"The universe\", max_new_tokens=50):\n","    model.eval()\n","    tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n","    model.reservoir.reset_state(1)\n","\n","    for _ in range(max_new_tokens):\n","        logits = model(tokens)\n","        next_token = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)\n","        tokens = torch.cat([tokens, next_token], dim=1)\n","    text = tokenizer.decode(tokens[0])\n","    return text\n","\n","print(generate_text(model, tokenizer, prompt=\"Artificial intelligence\"))\n"],"metadata":{"id":"Vgf8qHWsD3D8"},"execution_count":null,"outputs":[]}]}